# PySpark Exercises
A collection of hands-on exercises and examples for learning PySpark on Databricks. This repository covers everything from Spark basics to advanced transformations, SQL queries, DataFrames, and machine learning workflows. Designed to run directly in Databricks notebooks, the exercises provide a practical, cloud-ready way to master distributed data processing with Spark.

Key highlights:

Getting started with SparkSession in Databricks

Working with DataFrames, RDDs, and SQL

Data ingestion from CSV, JSON, and Parquet

Transformations and aggregations with PySpark

Using Databricks utilities (dbutils) for data access

Hands-on ETL and data engineering pipelines

Intro to Spark MLlib for machine learning

Whether you’re a beginner practicing PySpark basics or a data professional building production pipelines, this repo helps you learn PySpark the way it’s used in real-world Databricks environments.
